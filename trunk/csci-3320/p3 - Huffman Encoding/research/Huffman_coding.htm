<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" dir="ltr" lang="en"><head>

	
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
				<meta name="keywords" content="Huffman coding,Compression Methods,Compression Methods,Compression Formats,Compression Software Implementations,2006,A-law algorithm,ASCII,A Mathematical Theory of Communication,Acoustics,Adaptive Huffman coding">
		<link rel="shortcut icon" href="http://en.wikipedia.org/favicon.ico">
		<link rel="search" type="application/opensearchdescription+xml" href="http://en.wikipedia.org/w/opensearch_desc.php" title="Wikipedia (English)">
		<link rel="copyright" href="http://www.gnu.org/copyleft/fdl.html"><title>Huffman coding - Wikipedia, the free encyclopedia</title>
		
		<style type="text/css" media="screen,projection">/*<![CDATA[*/
			@import "/skins-1.5/common/shared.css?80";
			@import "/skins-1.5/monobook/main.css?80";
		/*]]>*/</style>
		<link rel="stylesheet" type="text/css" media="print" href="Huffman_coding_files/commonPrint.css">
		<link rel="stylesheet" type="text/css" media="handheld" href="Huffman_coding_files/handheld.css"><!--[if lt IE 5.5000]><style type="text/css">@import "/skins-1.5/monobook/IE50Fixes.css?80";</style><![endif]--><!--[if IE 5.5000]><style type="text/css">@import "/skins-1.5/monobook/IE55Fixes.css?80";</style><![endif]--><!--[if IE 6]><style type="text/css">@import "/skins-1.5/monobook/IE60Fixes.css?80";</style><![endif]--><!--[if IE 7]><style type="text/css">@import "/skins-1.5/monobook/IE70Fixes.css?80";</style><![endif]--><!--[if lt IE 7]><script type="text/javascript" src="/skins-1.5/common/IEFixes.js?80"></script>
		<meta http-equiv="imagetoolbar" content="no" /><![endif]-->
		
		
		
		
		
		
		<script type="text/javascript">/*<![CDATA[*/
var skin = "monobook";
var stylepath = "/skins-1.5";
var wgArticlePath = "/wiki/$1";
var wgScriptPath = "/w";
var wgScript = "/w/index.php";
var wgServer = "http://en.wikipedia.org";
var wgCanonicalNamespace = "";
var wgCanonicalSpecialPageName = false;
var wgNamespaceNumber = 0;
var wgPageName = "Huffman_coding";
var wgTitle = "Huffman coding";
var wgAction = "view";
var wgRestrictionEdit = [];
var wgRestrictionMove = [];
var wgArticleId = "13883";
var wgIsArticle = true;
var wgUserName = null;
var wgUserGroups = null;
var wgUserLanguage = "en";
var wgContentLanguage = "en";
var wgBreakFrames = false;
var wgCurRevisionId = "141582989";
/*]]>*/</script>
                
		<script type="text/javascript" src="Huffman_coding_files/wikibits.js"><!-- wikibits js --></script>
		<script type="text/javascript" src="Huffman_coding_files/index_002.php"><!-- site js --></script><script type="text/javascript" src="Huffman_coding_files/index.php"></script>
		<style type="text/css">/*<![CDATA[*/
@import "/w/index.php?title=MediaWiki:Common.css&usemsgcache=yes&action=raw&ctype=text/css&smaxage=2678400";
@import "/w/index.php?title=MediaWiki:Monobook.css&usemsgcache=yes&action=raw&ctype=text/css&smaxage=2678400";
@import "/w/index.php?title=-&action=raw&gen=css&maxage=2678400";
/*]]>*/</style><!-- Head Scripts -->
		
		<script type="text/javascript" src="Huffman_coding_files/ajax.js"></script></head><body class="mediawiki ns-0 ltr page-Huffman_coding">
	<div id="globalWrapper">
		<div id="column-content">
	<div id="content">
		<a name="top" id="top"></a>
		<div id="siteNotice"><script type="text/javascript" language="JavaScript">
<!--
document.writeln("\x3cdiv style=\"position:absolute; z-index:100; right:100px; top:-0px;\" class=\"metadata\" id=\"donate\"\x3e\n\x3cdiv style=\"text-align:right; font-size:80%\"\x3e\x3ci\x3eYour \x3cb\x3e\x3ca href=\"http://wikimediafoundation.org/wiki/Fundraising\" class=\"extiw\" title=\"wikimedia:Fundraising\"\x3econtinued donations\x3c/a\x3e\x3c/b\x3e keep Wikipedia running!\x3c/i\x3e\n\x3c/div\x3e\x3c/div\x3e\n");
-->
</script><div style="position: absolute; z-index: 100; right: 100px; top: 0px;" class="metadata" id="donate">
<div style="text-align: right; font-size: 80%;"><i>Your <b><a href="http://wikimediafoundation.org/wiki/Fundraising" class="extiw" title="wikimedia:Fundraising">continued donations</a></b> keep Wikipedia running!</i>
</div></div>

</div>		<h1 class="firstHeading">Huffman coding</h1>
		<div id="bodyContent">
			<h3 id="siteSub">From Wikipedia, the free encyclopedia</h3>
			<div id="contentSub"></div>
									<div id="jump-to-nav">Jump to: <a href="#column-one">navigation</a>, <a href="#searchInput">search</a></div>			<!-- start content -->
			<div class="tright">
<table>
<tbody><tr>
<td>
<div class="center">
<div class="thumb tnone">
<div class="thumbinner" style="width: 352px;"><a href="http://en.wikipedia.org/wiki/Image:Huffman_tree.svg" class="internal" title="Huffman tree generated from the exact frequencies of the text &quot;this is an example of a huffman tree&quot;. The frequencies and codes of each character are below. Encoding the sentence with this code requires 135 bits, not counting space for the tree."><img alt="Huffman tree generated from the exact frequencies of the text &quot;this is an example of a huffman tree&quot;. The frequencies and codes of each character are below. Encoding the sentence with this code requires 135 bits, not counting space for the tree." longdesc="/wiki/Image:Huffman_tree.svg" class="thumbimage" src="Huffman_coding_files/350px-Huffman_tree.png" height="189" width="350"></a>
<div class="thumbcaption">
<div class="magnify" style="float: right;"><a href="http://en.wikipedia.org/wiki/Image:Huffman_tree.svg" class="internal" title="Enlarge"><img src="Huffman_coding_files/magnify-clip.png" alt="" height="11" width="15"></a></div>
Huffman tree generated from the exact frequencies of the text "this is
an example of a huffman tree". The frequencies and codes of each
character are below. Encoding the sentence with this code requires 135
bits, not counting space for the tree.</div>
</div>
</div>
</div>
</td>
</tr>
<tr>
<td>
<table>
<tbody><tr>
<td>
<table class="wikitable">
<tbody><tr>
<th>Char</th>
<th>Freq</th>
<th>Code</th>
</tr>
<tr>
<td>space</td>
<td>7</td>
<td>111</td>
</tr>
<tr>
<td>a</td>
<td>4</td>
<td>010</td>
</tr>
<tr>
<td>e</td>
<td>4</td>
<td>000</td>
</tr>
<tr>
<td>f</td>
<td>3</td>
<td>1101</td>
</tr>
<tr>
<td>h</td>
<td>2</td>
<td>1010</td>
</tr>
<tr>
<td>i</td>
<td>2</td>
<td>1000</td>
</tr>
<tr>
<td>m</td>
<td>2</td>
<td>0111</td>
</tr>
<tr>
<td>n</td>
<td>2</td>
<td>0010</td>
</tr>
<tr>
<td>s</td>
<td>2</td>
<td>1011</td>
</tr>
<tr>
<td>t</td>
<td>2</td>
<td>0110</td>
</tr>
<tr>
<td>l</td>
<td>1</td>
<td>11001</td>
</tr>
<tr>
<td>o</td>
<td>1</td>
<td>00110</td>
</tr>
<tr>
<td>p</td>
<td>1</td>
<td>10011</td>
</tr>
<tr>
<td>r</td>
<td>1</td>
<td>11000</td>
</tr>
<tr>
<td>u</td>
<td>1</td>
<td>00111</td>
</tr>
<tr>
<td>x</td>
<td>1</td>
<td>10010</td>
</tr>
</tbody></table>
</td>
</tr>
</tbody></table>
</td>
</tr>
</tbody></table>
</div>
<p>In <a href="http://en.wikipedia.org/wiki/Computer_science" title="Computer science">computer science</a> and <a href="http://en.wikipedia.org/wiki/Information_theory" title="Information theory">information theory</a>, <b>Huffman coding</b> is an <a href="http://en.wikipedia.org/wiki/Entropy_encoding" title="Entropy encoding">entropy encoding</a> <a href="http://en.wikipedia.org/wiki/Algorithm" title="Algorithm">algorithm</a> used for <a href="http://en.wikipedia.org/wiki/Lossless_data_compression" title="Lossless data compression">lossless data compression</a>. The term refers to the use of a <a href="http://en.wikipedia.org/wiki/Variable-length_code" title="Variable-length code">variable-length code</a>
table for encoding a source symbol (such as a character in a file)
where the variable-length code table has been derived in a particular
way based on the estimated probability of occurrence for each possible
value of the source symbol. It was developed by <a href="http://en.wikipedia.org/wiki/David_A._Huffman" title="David A. Huffman">David A. Huffman</a> while he was a <a href="http://en.wikipedia.org/wiki/Doctor_of_Philosophy" title="Doctor of Philosophy">Ph.D.</a> student at <a href="http://en.wikipedia.org/wiki/Massachusetts_Institute_of_Technology" title="Massachusetts Institute of Technology">MIT</a>,
and published in the 1952 paper "A Method for the Construction of
Minimum-Redundancy Codes." Huffman became a member of the MIT faculty
upon graduation and was later the founding member of the Computer
Science Department at the <a href="http://en.wikipedia.org/wiki/University_of_California%2C_Santa_Cruz" title="University of California, Santa Cruz">University of California, Santa Cruz</a>, now a part of the Baskin School of Engineering.</p>
<p>Huffman coding uses a specific method for choosing the representation for each symbol, resulting in a <a href="http://en.wikipedia.org/wiki/Prefix-free_code" title="Prefix-free code">prefix-free code</a>
(sometimes called "prefix codes") (that is, the bit string representing
some particular symbol is never a prefix of the bit string representing
any other symbol) that expresses the most common characters using
shorter strings of bits than are used for less common source symbols.
Huffman was able to design the most efficient compression method of
this type: no other mapping of individual source symbols to unique
strings of bits will produce a smaller average output size when the
actual symbol frequencies agree with those used to create the code. A
method was later found to do this in <a href="http://en.wikipedia.org/wiki/Linear_time" title="Linear time">linear time</a> if input probabilities (also known as <i>weights</i>) are sorted.</p>
<p>For a set of symbols with a uniform probability distribution and a number of members which is a <a href="http://en.wikipedia.org/wiki/Power_of_two" title="Power of two">power of two</a>, Huffman coding is equivalent to simple binary <a href="http://en.wikipedia.org/wiki/Block_code" title="Block code">block encoding</a>, e.g., <a href="http://en.wikipedia.org/wiki/ASCII" title="ASCII">ASCII</a>
coding. Huffman coding is such a widespread method for creating
prefix-free codes that the term "Huffman code" is widely used as a
synonym for "prefix-free code" even when such a code is not produced by
Huffman's algorithm.</p>
<p>Although Huffman coding is optimal for a symbol-by-symbol coding
with a known input probability distribution, its optimality can
sometimes accidentally be over-stated. For example, <a href="http://en.wikipedia.org/wiki/Arithmetic_coding" title="Arithmetic coding">arithmetic coding</a> and <a href="http://en.wikipedia.org/wiki/LZW" title="LZW">LZW</a>
coding often have better compression capability. Both these methods can
combine an arbitrary number of symbols for more efficient coding, and
generally adapt to the actual input statistics, the latter of which is
useful when input probabilities are not precisely known.</p>
<table id="toc" class="toc" summary="Contents">
<tbody><tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
 <span class="toctoggle">[<a href="javascript:toggleToc()" class="internal" id="togglelink">hide</a>]</span></div>
<ul>
<li class="toclevel-1"><a href="#History"><span class="tocnumber">1</span> <span class="toctext">History</span></a></li>
<li class="toclevel-1"><a href="#Problem_definition"><span class="tocnumber">2</span> <span class="toctext">Problem definition</span></a>
<ul>
<li class="toclevel-2"><a href="#Informal_description"><span class="tocnumber">2.1</span> <span class="toctext">Informal description</span></a></li>
<li class="toclevel-2"><a href="#Formalized_description"><span class="tocnumber">2.2</span> <span class="toctext">Formalized description</span></a></li>
<li class="toclevel-2"><a href="#Samples"><span class="tocnumber">2.3</span> <span class="toctext">Samples</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Basic_technique"><span class="tocnumber">3</span> <span class="toctext">Basic technique</span></a></li>
<li class="toclevel-1"><a href="#Main_properties"><span class="tocnumber">4</span> <span class="toctext">Main properties</span></a></li>
<li class="toclevel-1"><a href="#Variations"><span class="tocnumber">5</span> <span class="toctext">Variations</span></a>
<ul>
<li class="toclevel-2"><a href="#n-ary_Huffman_coding"><span class="tocnumber">5.1</span> <span class="toctext">n-ary Huffman coding</span></a></li>
<li class="toclevel-2"><a href="#Adaptive_Huffman_coding"><span class="tocnumber">5.2</span> <span class="toctext">Adaptive Huffman coding</span></a></li>
<li class="toclevel-2"><a href="#Huffman_template_algorithm"><span class="tocnumber">5.3</span> <span class="toctext">Huffman template algorithm</span></a></li>
<li class="toclevel-2"><a href="#Length-limited_Huffman_coding"><span class="tocnumber">5.4</span> <span class="toctext">Length-limited Huffman coding</span></a></li>
<li class="toclevel-2"><a href="#Huffman_coding_with_unequal_letter_costs"><span class="tocnumber">5.5</span> <span class="toctext">Huffman coding with unequal letter costs</span></a></li>
<li class="toclevel-2"><a href="#Optimal_alphabetic_binary_trees_.28Hu-Tucker_coding_and_the_canonical_Huffman_code.29"><span class="tocnumber">5.6</span> <span class="toctext">Optimal alphabetic binary trees (Hu-Tucker coding and the canonical Huffman code)</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="#Applications"><span class="tocnumber">6</span> <span class="toctext">Applications</span></a></li>
<li class="toclevel-1"><a href="#See_also"><span class="tocnumber">7</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1"><a href="#References"><span class="tocnumber">8</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1"><a href="#External_links"><span class="tocnumber">9</span> <span class="toctext">External links</span></a></li>
</ul>
</td>
</tr>
</tbody></table>
<script type="text/javascript">
//<![CDATA[
 if (window.showTocToggle) { var tocShowText = "show"; var tocHideText = "hide"; showTocToggle(); } 
//]]>
</script>
<p><a name="History" id="History"></a></p>
<h2><span class="editsection">[<a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=edit&amp;section=1" title="Edit section: History">edit</a>]</span> <span class="mw-headline">History</span></h2>
<p>In 1951, <a href="http://en.wikipedia.org/wiki/David_A._Huffman" title="David A. Huffman">David A. Huffman</a> and his MIT information theory classmates were given the choice of a term paper or a final exam. The professor, <a href="http://en.wikipedia.org/wiki/Robert_M._Fano" title="Robert M. Fano">Robert M. Fano</a>,
assigned a term paper on the problem of finding the most efficient
binary code. Huffman, unable to prove any codes were the most
efficient, was about to give up and start studying for the final when
he hit upon the idea of using a frequency-sorted <a href="http://en.wikipedia.org/wiki/Binary_tree" title="Binary tree">binary tree</a> and quickly proved this method the most efficient.</p>
<p>In doing so, the student outdid his professor, who had worked with <a href="http://en.wikipedia.org/wiki/Information_theory" title="Information theory">information theory</a> inventor <a href="http://en.wikipedia.org/wiki/Claude_Shannon" title="Claude Shannon">Claude Shannon</a> to develop a similar code. Huffman avoided the major flaw of the suboptimal <a href="http://en.wikipedia.org/wiki/Shannon-Fano_coding" title="Shannon-Fano coding">Shannon-Fano coding</a> by building the tree from the bottom up instead of from the top down.</p>
<p><a name="Problem_definition" id="Problem_definition"></a></p>
<h2><span class="editsection">[<a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=edit&amp;section=2" title="Edit section: Problem definition">edit</a>]</span> <span class="mw-headline">Problem definition</span></h2>
<p><a name="Informal_description" id="Informal_description"></a></p>
<h4><span class="editsection">[<a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=edit&amp;section=3" title="Edit section: Informal description">edit</a>]</span> <span class="mw-headline">Informal description</span></h4>
<p><b>Given</b>. A set of symbols and their weights (usually probabilities).<br>
<b>Find</b>. A <a href="http://en.wikipedia.org/wiki/Prefix_code" title="Prefix code">prefix-free binary code</a> (a set of codewords) with minimum <a href="http://en.wikipedia.org/wiki/Expected_value" title="Expected value">expected</a> codeword length (equivalently, a tree with minimum <a href="http://en.wikipedia.org/w/index.php?title=Weighted_path_length&amp;action=edit" class="new" title="Weighted path length">weighted path length</a>).<br></p>
<p><a name="Formalized_description" id="Formalized_description"></a></p>
<h4><span class="editsection">[<a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=edit&amp;section=4" title="Edit section: Formalized description">edit</a>]</span> <span class="mw-headline">Formalized description</span></h4>
<p><b>Input</b>.<br>
Alphabet <img class="tex" src="Huffman_coding_files/d0970150791f5003694e9cae98ce9f41.png" alt="A = \left\{a_{1},a_{2},\cdots,a_{n}\right\}">, which is the symbol alphabet of size <span class="texhtml"><i>n</i></span>.<br>
Set <img class="tex" src="Huffman_coding_files/42e67ab6409cbac8d50013098e1a9983.png" alt="W = \left\{w_{1},w_{2},\cdots,w_{n}\right\}">, which is the set of the (positive) symbol weights (usually probabilities), i.e. <img class="tex" src="Huffman_coding_files/db0f7d56e161aa7daa78851955793040.png" alt="w_{i} = \mathrm{weight}\left(a_{i}\right), 1\leq i \leq n">.<br>
<br>
<b>Output</b>.<br>
Code <img class="tex" src="Huffman_coding_files/9eeded7f92ea74cb4703e9ecaffa9194.png" alt="C\left(A,W\right) = \left\{c_{1},c_{2},\cdots,c_{n}\right\}">, which is the set of (binary) codewords, where <span class="texhtml"><i>c</i><sub><i>i</i></sub></span> is the codeword for <img class="tex" src="Huffman_coding_files/cd63c7aa48044268dbc7b7ef38c2fc70.png" alt="a_{i}, 1 \leq i \leq n">.<br>
<br>
<b>Goal</b>.<br>
Let <img class="tex" src="Huffman_coding_files/f48361a2be7c46c614d13df91f51678a.png" alt="L\left(C\right) = \sum_{i=1}^{n}{w_{i}\times\mathrm{length}\left(c_{i}\right)}"> be the weighted path length of code <span class="texhtml"><i>C</i></span>. Condition: <img class="tex" src="Huffman_coding_files/324251b7776dbc6d2ae97807f1ef8529.png" alt="L\left(C\right) \leq L\left(T\right)"> for any code <img class="tex" src="Huffman_coding_files/8cf9d64bf42cdfcec84ccc50fff211cf.png" alt="T\left(A,W\right)">.</p>
<p><a name="Samples" id="Samples"></a></p>
<h4><span class="editsection">[<a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=edit&amp;section=5" title="Edit section: Samples">edit</a>]</span> <span class="mw-headline">Samples</span></h4>
<table class="wikitable">
<tbody><tr>
<th rowspan="2" style="background: rgb(239, 239, 239) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial;">Input (<i>A</i>, <i>W</i>)</th>
<th style="background: rgb(239, 239, 239) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial; font-weight: normal;">Symbol (<i>a</i><sub><small><i>i</i></small></sub>)</th>
<td style="background: rgb(239, 239, 239) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial;" align="center">a</td>
<td style="background: rgb(239, 239, 239) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial;" align="center">b</td>
<td style="background: rgb(239, 239, 239) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial;" align="center">c</td>
<td style="background: rgb(239, 239, 239) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial;" align="center">d</td>
<td style="background: rgb(239, 239, 239) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial;" align="center">e</td>
<th style="background: rgb(239, 239, 239) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial;">Sum</th>
</tr>
<tr>
<th style="background: rgb(239, 239, 239) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial; font-weight: normal;">Weights (<i>w</i><sub><small><i>i</i></small></sub>)</th>
<td align="center">0.10</td>
<td align="center">0.15</td>
<td align="center">0.30</td>
<td align="center">0.16</td>
<td align="center">0.29</td>
<td align="center">= 1</td>
</tr>
<tr>
<th rowspan="3" style="background: rgb(239, 239, 239) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial;">Output <i>C</i></th>
<th style="background: rgb(239, 239, 239) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial; font-weight: normal;">Codewords (<i>c</i><sub><small><i>i</i></small></sub>)</th>
<td align="center"><tt>000</tt></td>
<td align="center"><tt>001</tt></td>
<td align="center"><tt>10</tt></td>
<td align="center"><tt>01</tt></td>
<td align="center"><tt>11</tt></td>
<td rowspan="2">&nbsp;</td>
</tr>
<tr>
<th style="background: rgb(239, 239, 239) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial; font-weight: normal;">Codeword length (in bits)<br>
(<i>l</i><sub><small><i>i</i></small></sub>)</th>
<td align="center">3</td>
<td align="center">3</td>
<td align="center">2</td>
<td align="center">2</td>
<td align="center">2</td>
</tr>
<tr>
<th style="background: rgb(239, 239, 239) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial; font-weight: normal;">Weighted path length<br>
(<i>l</i><sub><small><i>i</i></small></sub> <i>w</i><sub><small><i>i</i></small></sub> )</th>
<td align="center">0.30</td>
<td align="center">0.45</td>
<td align="center">0.60</td>
<td align="center">0.32</td>
<td align="center">0.58</td>
<td align="center"><i>L</i>(<i>C</i>) = 2.25</td>
</tr>
<tr>
<th rowspan="3" style="background: rgb(239, 239, 239) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial;">Optimality</th>
<th style="background: rgb(239, 239, 239) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial; font-weight: normal;">Probability budget<br>
(2<sup>-<i>l</i><sub><small><i>i</i></small></sub></sup>)</th>
<td align="center">1/8</td>
<td align="center">1/8</td>
<td align="center">1/4</td>
<td align="center">1/4</td>
<td align="center">1/4</td>
<td align="center">= 1.00</td>
</tr>
<tr>
<th style="background: rgb(239, 239, 239) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial; font-weight: normal;">Information content (in bits)<br>
(−<b>log</b><sub><small>2</small></sub> <i>w</i><sub><small><i>i</i></small></sub>) ≈</th>
<td align="center">3.32</td>
<td align="center">2.74</td>
<td align="center">1.74</td>
<td align="center">2.64</td>
<td align="center">1.79</td>
<td align="center">&nbsp;</td>
</tr>
<tr>
<th style="background: rgb(239, 239, 239) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial; font-weight: normal;">Entropy<br>
(−<i>w</i><sub><small><i>i</i></small></sub> <b>log</b><sub><small>2</small></sub> <i>w</i><sub><small><i>i</i></small></sub>)</th>
<td align="center">0.332</td>
<td align="center">0.411</td>
<td align="center">0.521</td>
<td align="center">0.423</td>
<td align="center">0.518</td>
<td align="center"><i>H</i>(<i>A</i>) = 2.205</td>
</tr>
</tbody></table>
<p>For any code that is <i>biunique</i>, meaning that the code is <i>uniquely decodeable</i>,
the sum of the probability budgets across all symbols is always less
than or equal to one. In this example, the sum is strictly equal to
one; as a result, the code is termed a <i>complete</i> code. If this
is not the case, you can always derive an equivalent code by adding
extra symbols (with associated null probabilities), to make the code
complete while keeping it <i>biunique</i>.</p>
<p>As defined by <a href="http://en.wikipedia.org/wiki/A_Mathematical_Theory_of_Communication" title="A Mathematical Theory of Communication">Shannon (1948)</a>, the information content <i>h</i> (in bits) of each symbol <i>a</i><sub>i</sub> with non-null probability is</p>
<dl>
<dd><img class="tex" src="Huffman_coding_files/4acaf603caa4acebf7c80e6c4efa2f8d.png" alt="h(a_i) = \log_2{1 \over w_i}"></dd>
</dl>
<p>The information content of symbols with null probability is not
defined, but in practice can be defined as any finite value because
this information will be absent from the encoded message (unless the
message <i>A</i> has an infinite symbol length, but in this case these symbols have an infinitesimal positive probability 0<sup><small>+</small></sup>).</p>
<p>The <a href="http://en.wikipedia.org/wiki/Information_entropy" title="Information entropy">entropy</a> <i>H</i> (in bits) is the weighted sum, across all symbols <i>a</i><sub><small><i>i</i></small></sub> with non-zero probability <i>w</i><sub><small><i>i</i></small></sub>, of the information content of each symbol:</p>
<dl>
<dd><img class="tex" src="Huffman_coding_files/6176bebfd5aa0cee326f7c87f6d2c01c.png" alt="H(A) = \sum_{w_i &gt; 0} w_i h(a_i) = \sum_{w_i &gt; 0} w_i \log_2{1 \over w_i} = - \sum_{w_i &gt; 0} w_i \log_2{w_i}"></dd>
</dl>
<p>All symbols with zero probability have in theory a positive infinite
entropy, but as they are necessarily absent from the original message
to be encoded, they don't contribute to the entropy of the encoded
message (unless the message is infinite)&nbsp;; so they could be made
equivalent to a zero entropy within the sum above, removing the
restriction on the suitable indices.</p>
<p>As a consequence of Shannon's <a href="http://en.wikipedia.org/wiki/Source_coding_theorem" title="Source coding theorem">Source coding theorem</a>,
the entropy is a measure of the smallest codeword length that is
theoretically possible for the given alphabet with associated weights.
In this example, the weighted average codeword length is 2.25 bits per
symbol, only slightly larger than the calculated entropy of 2.205 bits
per symbol. So not only is this code optimal in the sense that no other
feasible code performs better, but it is very close to the theoretical
limit established by Shannon.</p>
<p>Note that, in general, a Huffman code need not be unique, but it is always one of the codes minimizing <span class="texhtml"><i>L</i>(<i>C</i>)</span>.</p>
<p><a name="Basic_technique" id="Basic_technique"></a></p>
<h2><span class="editsection">[<a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=edit&amp;section=6" title="Edit section: Basic technique">edit</a>]</span> <span class="mw-headline">Basic technique</span></h2>
<div class="thumb tright">
<div class="thumbinner" style="width: 252px;"><a href="http://en.wikipedia.org/wiki/Image:Huffman_coding_example.svg" class="internal" title="Assume you have a source generating 4 different symbols {a1,a2,a3,a4} with probability {0.4;0.35;0.2;0.05}. Generate a binary tree from left to right taking the two less probable symbols, putting them together to form another equivalent symbol having a probability that equals the sum of the two symbols. Keep on doing it until you have just one symbol. Then read the tree backwards, from right to left, assigning different bits to different branches.The final Huffman code is:    Symbol  Code   a1  0   a2  10   a3  111   a4  110   The standard way to represent a signal made of 4 symbols is by using 2 bits/symbol, but the entropy of the source is 1.73 bits/symbol. If this Huffman code is used to represent the signal, then the entropy is lowered to 1.83 bits/symbol; it is still far from the theoretical limit because the probabilities of the symbols are different from negative powers of two."><img alt="Assume you have a source generating 4 different symbols {a1,a2,a3,a4} with probability {0.4;0.35;0.2;0.05}. Generate a binary tree from left to right taking the two less probable symbols, putting them together to form another equivalent symbol having a probability that equals the sum of the two symbols. Keep on doing it until you have just one symbol. Then read the tree backwards, from right to left, assigning different bits to different branches.The final Huffman code is:    Symbol  Code   a1  0   a2  10   a3  111   a4  110   The standard way to represent a signal made of 4 symbols is by using 2 bits/symbol, but the entropy of the source is 1.73 bits/symbol. If this Huffman code is used to represent the signal, then the entropy is lowered to 1.83 bits/symbol; it is still far from the theoretical limit because the probabilities of the symbols are different from negative powers of two." longdesc="/wiki/Image:Huffman_coding_example.svg" class="thumbimage" src="Huffman_coding_files/250px-Huffman_coding_example.png" height="120" width="250"></a>
<div class="thumbcaption">
<div class="magnify" style="float: right;"><a href="http://en.wikipedia.org/wiki/Image:Huffman_coding_example.svg" class="internal" title="Enlarge"><img src="Huffman_coding_files/magnify-clip.png" alt="" height="11" width="15"></a></div>
Assume you have a source generating 4 different symbols <span class="texhtml">{<i>a</i><sub>1</sub>,<i>a</i><sub>2</sub>,<i>a</i><sub>3</sub>,<i>a</i><sub>4</sub>}</span> with probability <span class="texhtml">{0.4;0.35;0.2;0.05}</span>.
Generate a binary tree from left to right taking the two less probable
symbols, putting them together to form another equivalent symbol having
a probability that equals the sum of the two symbols. Keep on doing it
until you have just one symbol. Then read the tree backwards, from
right to left, assigning different bits to different branches.The final
Huffman code is:
<table class="wikitable">
<tbody><tr>
<th>Symbol</th>
<th>Code</th>
</tr>
<tr>
<td>a1</td>
<td>0</td>
</tr>
<tr>
<td>a2</td>
<td>10</td>
</tr>
<tr>
<td>a3</td>
<td>111</td>
</tr>
<tr>
<td>a4</td>
<td>110</td>
</tr>
</tbody></table>
The standard way to represent a signal made of 4 symbols is by using 2 bits/symbol, but the <a href="http://en.wikipedia.org/wiki/Information_entropy" title="Information entropy">entropy</a>
of the source is 1.73 bits/symbol. If this Huffman code is used to
represent the signal, then the entropy is lowered to 1.83 bits/symbol;
it is still far from the theoretical limit because the probabilities of
the symbols are different from negative powers of two.</div>
</div>
</div>
<p>The technique works by creating a <a href="http://en.wikipedia.org/wiki/Binary_tree" title="Binary tree">binary tree</a> of nodes. These can be stored in a regular <a href="http://en.wikipedia.org/wiki/Array" title="Array">array</a>, the size of which depends on the number of symbols(N). A node can be either a <a href="http://en.wikipedia.org/wiki/Leaf_node" title="Leaf node">leaf node</a> or an <a href="http://en.wikipedia.org/wiki/Internal_node" title="Internal node">internal node</a>. Initially, all nodes are leaf nodes, which contain the <b>symbol</b> itself, the <b>weight</b> (frequency of appearance) of the symbol and optionally, a link to a <b>parent</b> node which makes it easy to read the code (in reverse) starting from a leaf node. Internal nodes contain symbol <b>weight</b>, links to <b>two child nodes</b> and the optional link to a <b>parent</b>
node. As a common convention, bit '0' represents following the left
child and bit '1' represents following the right child. A finished tree
has N leaf nodes and N−1 internal nodes.</p>
<p>A <a href="http://en.wikipedia.org/wiki/Linear_time" title="Linear time">linear-time</a>* method to create a Huffman tree is to use two <a href="http://en.wikipedia.org/wiki/Queue_%28data_structure%29" title="Queue (data structure)">queues</a>,
the first one containing the initial weights (along with pointers to
the associated leaves), and combined weights (along with pointers to
the trees) being put in the back of the second queue. This assures that
the lowest weight is always kept at the front of one of the two queues.</p>
<p>Creating the tree:</p>
<ol>
<li>Start with as many leaves as there are symbols.</li>
<li>Enqueue all leaf nodes into the first queue (by probability in
increasing order so that the least likely item is in the head of the
queue).</li>
<li>While there is more than one node in the queues:
<ol>
<li>Dequeue the two nodes with the lowest weight.</li>
<li>Create a new internal node, with the two just-removed nodes as
children (either node can be either child) and the sum of their weights
as the new weight.</li>
<li>Enqueue the new node into the rear of the second queue.</li>
</ol>
</li>
<li>The remaining node is the root node; the tree has now been generated.</li>
</ol>
<p>It is generally beneficial to minimize the variance of codeword
length. For example, a communication buffer receiving Huffman-encoded
data may need to be larger to deal with especially long symbols if the
tree is especially unbalanced. To minimize variance, simply break ties
between queues by choosing the item in the first queue. This
modification will retain the mathematical optimality of the Huffman
coding while both minimizing variance and minimizing the length of the
longest character code.</p>
<p>* This method is linear time assuming that you already have the leaf nodes sorted by initial weight. If not, <a href="http://en.wikipedia.org/wiki/Sorting_algorithm" title="Sorting algorithm">sorting</a> them will take <span class="texhtml"><i>O</i>(<i>n</i>log<i>n</i>)</span> time.</p>
<p><a name="Main_properties" id="Main_properties"></a></p>
<h2><span class="editsection">[<a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=edit&amp;section=7" title="Edit section: Main properties">edit</a>]</span> <span class="mw-headline">Main properties</span></h2>
<p>The frequencies used can be generic ones for the application domain
that are based on average experience, or they can be the actual
frequencies found in the text being compressed. (This variation
requires that a <a href="http://en.wikipedia.org/w/index.php?title=Frequency_table&amp;action=edit" class="new" title="Frequency table">frequency table</a>
or other hint as to the encoding must be stored with the compressed
text; implementations employ various tricks to store tables
efficiently.)</p>
<p>Huffman coding is optimal when the probability of each input symbol
is a negative power of two. Prefix-free codes tend to have slight
inefficiency on small alphabets, where probabilities often fall between
these optimal points. "Blocking", or expanding the alphabet size by
coalescing multiple symbols into "words" of fixed or variable-length
before Huffman coding, usually helps, especially when adjacent symbols
are correlated (as in the case of natural language text). The worst
case for Huffman coding can happen when the probability of a symbol
exceeds 2<sup>-1</sup> = 0.5, making the upper limit of inefficiency unbounded. These situations often respond well to a form of blocking called <a href="http://en.wikipedia.org/wiki/Run-length_encoding" title="Run-length encoding">run-length encoding</a>.</p>
<p><a href="http://en.wikipedia.org/wiki/Arithmetic_coding" title="Arithmetic coding">Arithmetic coding</a>
produces slight gains over Huffman coding, but in practice these gains
have seldom been large enough to offset arithmetic coding's higher
computational complexity and <a href="http://en.wikipedia.org/wiki/Patent" title="Patent">patent</a> <a href="http://en.wikipedia.org/wiki/Royalties" title="Royalties">royalties</a>. (As of July <a href="http://en.wikipedia.org/wiki/2006" title="2006">2006</a>, <a href="http://en.wikipedia.org/wiki/IBM" title="IBM">IBM</a> owns patents on many methods of arithmetic coding in several jurisdictions; see <a href="http://en.wikipedia.org/wiki/Arithmetic_coding#US_patents_on_arithmetic_coding" title="Arithmetic coding">US patents on arithmetic coding</a>.)</p>
<p><a name="Variations" id="Variations"></a></p>
<h2><span class="editsection">[<a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=edit&amp;section=8" title="Edit section: Variations">edit</a>]</span> <span class="mw-headline">Variations</span></h2>
<p>Many variations of Huffman coding exist, some of which use a
Huffman-like algorithm, and others of which find optimal prefix codes
(while, for example, putting different restrictions on the output).
Note that, in the latter case, the method need not be Huffman-like,
and, indeed, need not even be <a href="http://en.wikipedia.org/wiki/Polynomial_time" title="Polynomial time">polynomial time</a>.
An exhaustive list of papers on Huffman coding on its variations is
given by "Code and Parse Trees for Lossless Source Encoding"<a href="http://scholar.google.com/scholar?hl=en&amp;lr=&amp;cluster=6556734736002074338" class="external autonumber" title="http://scholar.google.com/scholar?hl=en&amp;lr=&amp;cluster=6556734736002074338" rel="nofollow">[1]</a>.</p>
<p><a name="n-ary_Huffman_coding" id="n-ary_Huffman_coding"></a></p>
<h3><span class="editsection">[<a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=edit&amp;section=9" title="Edit section: n-ary Huffman coding">edit</a>]</span> <span class="mw-headline"><i>n</i>-ary Huffman coding</span></h3>
<p>The <b><i>n</i>-ary Huffman</b> algorithm uses the {0, 1, ..., <i>n</i> − 1} alphabet to encode message and build an <i>n</i>-ary tree. This approach was considered by Huffman in his original paper.</p>
<p><a name="Adaptive_Huffman_coding" id="Adaptive_Huffman_coding"></a></p>
<h3><span class="editsection">[<a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=edit&amp;section=10" title="Edit section: Adaptive Huffman coding">edit</a>]</span> <span class="mw-headline">Adaptive Huffman coding</span></h3>
<p>A variation called <b><a href="http://en.wikipedia.org/wiki/Adaptive_Huffman_coding" title="Adaptive Huffman coding">adaptive Huffman coding</a></b>
calculates the frequencies dynamically based on recent actual
frequencies in the source string. This is somewhat related to the <a href="http://en.wikipedia.org/wiki/LZ77" title="LZ77">LZ</a> family of algorithms.</p>
<p><a name="Huffman_template_algorithm" id="Huffman_template_algorithm"></a></p>
<h3><span class="editsection">[<a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=edit&amp;section=11" title="Edit section: Huffman template algorithm">edit</a>]</span> <span class="mw-headline">Huffman template algorithm</span></h3>
<p>Most often, the weights used in implementations of Huffman coding
represent numeric probabilities, but the algorithm given above does not
require this; it requires only a way to order weights and to add them.
The <b>Huffman template algorithm</b> enables one to use any kind of
weights (costs, frequencies, pairs of weights, non-numerical weights)
and one of many combining methods (not just addition). Such algorithms
can solve other minimization problems, such as minimizing <img class="tex" src="Huffman_coding_files/93f6a8cf382b97ccad472e4b2816479e.png" alt="\max_i\left[w_{i}+\mathrm{length}\left(c_{i}\right)\right]"> , a problem first applied to circuit design<a href="http://citeseer.ist.psu.edu/context/665634/0" class="external autonumber" title="http://citeseer.ist.psu.edu/context/665634/0" rel="nofollow">[2]</a>.</p>
<p><a name="Length-limited_Huffman_coding" id="Length-limited_Huffman_coding"></a></p>
<h3><span class="editsection">[<a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=edit&amp;section=12" title="Edit section: Length-limited Huffman coding">edit</a>]</span> <span class="mw-headline">Length-limited Huffman coding</span></h3>
<p><b>Length-limited Huffman coding</b> is a variant where the goal is
still to achieve a minimum weighted path length, but there is an
additional restriction that the length of each codeword must be less
than a given constant. The <a href="http://en.wikipedia.org/wiki/Package-merge_algorithm" title="Package-merge algorithm">package-merge</a> algorithm solves this problem with a simple <a href="http://en.wikipedia.org/wiki/Greedy_algorithm" title="Greedy algorithm">greedy</a> approach very similar to that used by Huffman's algorithm. Its time complexity is <span class="texhtml"><i>O</i>(<i>n</i><i>L</i>)</span>, where <span class="texhtml"><i>L</i></span>
is the maximum length of a codeword. No algorithm is known to solve
this problem with the same efficiency as conventional Huffman coding,</p>
<p><a name="Huffman_coding_with_unequal_letter_costs" id="Huffman_coding_with_unequal_letter_costs"></a></p>
<h3><span class="editsection">[<a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=edit&amp;section=13" title="Edit section: Huffman coding with unequal letter costs">edit</a>]</span> <span class="mw-headline">Huffman coding with unequal letter costs</span></h3>
<p>In the standard Huffman coding problem, it is assumed that each
symbol in the set that the code words are constructed from has an equal
cost to transmit: a code word whose length is <i>N</i> digits will always have a cost of <i>N</i>,
no matter how many of those digits are 0s, how many are 1s, etc. When
working under this assumption, minimizing the total cost of the message
and minimizing the total number of digits are the same thing.</p>
<p><i>Huffman coding with unequal letter costs</i> is the
generalization in which this assumption is no longer assumed true: the
letters of the encoding alphabet may have non-uniform lengths, due to
characteristics of the transmission medium. An example is the encoding
alphabet of <a href="http://en.wikipedia.org/wiki/Morse_code" title="Morse code">Morse code</a>,
where a 'dash' takes longer to send than a 'dot', and therefore the
cost of a dash in transmission time is higher. The goal is still to
minimize the weighted average codeword length, but it is no longer
sufficient just to minimize the number of symbols used by the message.
No algorithm is known to solve this in the same manner or with the same
efficiency as conventional Huffman coding.</p>
<p><a name="Optimal_alphabetic_binary_trees_.28Hu-Tucker_coding_and_the_canonical_Huffman_code.29" id="Optimal_alphabetic_binary_trees_.28Hu-Tucker_coding_and_the_canonical_Huffman_code.29"></a></p>
<h3><span class="editsection">[<a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=edit&amp;section=14" title="Edit section: Optimal alphabetic binary trees (Hu-Tucker coding and the canonical Huffman code)">edit</a>]</span> <span class="mw-headline">Optimal alphabetic binary trees (Hu-Tucker coding and the canonical Huffman code)</span></h3>
<p>In the standard Huffman coding problem, it is assumed that any
codeword can correspond to any input symbol. In the alphabetic version,
the alphabetic order of inputs and outputs must be identical. Thus, for
example, <img class="tex" src="Huffman_coding_files/ee619c1ffa099c4a4e06ae20f61986aa.png" alt="A = \left\{a,b,c\right\}"> could not be assigned code <img class="tex" src="Huffman_coding_files/3c08049a6e2fbfd3ea8ff8c3adeadb6f.png" alt="H\left(A,C\right) = \left\{00,1,01\right\}">, but instead should be assigned either <img class="tex" src="Huffman_coding_files/7948394196623ad1d7ef20ba0cc0716f.png" alt="H\left(A,C\right) =\left\{00,01,1\right\}"> or <img class="tex" src="Huffman_coding_files/66a6f483854877bf5ff0711c7dff8a7f.png" alt="H\left(A,C\right) = \left\{0,10,11\right\}">. This is also known as the <b>Hu-Tucker</b> problem, after the authors of the paper presenting the first <a href="http://en.wikipedia.org/wiki/Linearithmic" title="Linearithmic">linearithmic</a>
solution to this optimal binary alphabetic problem, which has some
similarities to Huffman algorithm, but is not a variation of this
algorithm. These optimal alphabetic binary trees are often used as <a href="http://en.wikipedia.org/wiki/Binary_search_tree" title="Binary search tree">binary search trees</a>.
If weights corresponding to the alphabetically ordered inputs are in
numerical order, the Huffman code has the same lengths as the optimal
alphabetic code, which can be found from calculating these lengths. The
resulting alphabetic code is sometimes called the <i><a href="http://en.wikipedia.org/wiki/Canonical_Huffman_code" title="Canonical Huffman code">canonical Huffman code</a></i>
and is often the code used in practice, due to ease of
encoding/decoding. The technique for finding this code is sometimes
called <b>Huffman-Shannon-Fano coding</b>, since it is optimal like Huffman coding, but alphabetic in weight probability, like <a href="http://en.wikipedia.org/wiki/Shannon-Fano_coding" title="Shannon-Fano coding">Shannon-Fano coding</a>. The Huffman-Shannon-Fano code corresponding to the example is <span class="texhtml">{000,001,01,10,11}</span>, which, having the same codeword lengths as the original solution, is also optimal.</p>
<p><a name="Applications" id="Applications"></a></p>
<h2><span class="editsection">[<a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=edit&amp;section=15" title="Edit section: Applications">edit</a>]</span> <span class="mw-headline">Applications</span></h2>
<p><a href="http://en.wikipedia.org/wiki/Arithmetic_coding" title="Arithmetic coding">Arithmetic coding</a>
can be viewed as a generalization of Huffman coding; indeed, in
practice arithmetic coding is often preceded by Huffman coding, as it
is easier to find an arithmetic code for a binary input than for a
nonbinary input. Also, although arithmetic coding offers better
compression performance than Huffman coding, Huffman coding is still in
wide use because of its simplicity, high speed and lack of encumbrance
by <a href="http://en.wikipedia.org/wiki/Patent" title="Patent">patents</a>.</p>
<p>Huffman coding today is often used as a "back-end" to some other compression method. <a href="http://en.wikipedia.org/wiki/DEFLATE_%28algorithm%29" title="DEFLATE (algorithm)">DEFLATE</a> (<a href="http://en.wikipedia.org/wiki/PKZIP" title="PKZIP">PKZIP</a>'s algorithm) and multimedia <a href="http://en.wikipedia.org/wiki/Codec" title="Codec">codecs</a> such as <a href="http://en.wikipedia.org/wiki/JPEG" title="JPEG">JPEG</a> and <a href="http://en.wikipedia.org/wiki/MP3" title="MP3">MP3</a> have a front-end model and <a href="http://en.wikipedia.org/wiki/Quantization_%28signal_processing%29" title="Quantization (signal processing)">quantization</a> followed by Huffman coding.</p>
<p><a name="See_also" id="See_also"></a></p>
<h2><span class="editsection">[<a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=edit&amp;section=16" title="Edit section: See also">edit</a>]</span> <span class="mw-headline">See also</span></h2>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Modified_Huffman_coding" title="Modified Huffman coding">Modified Huffman coding</a> - used in <a href="http://en.wikipedia.org/wiki/Fax_machines" title="Fax machines">fax machines</a></li>
<li><a href="http://en.wikipedia.org/wiki/Shannon-Fano_coding" title="Shannon-Fano coding">Shannon-Fano coding</a></li>
<li><a href="http://en.wikipedia.org/wiki/Data_compression" title="Data compression">Data compression</a></li>
</ul>
<p><a name="References" id="References"></a></p>
<h2><span class="editsection">[<a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=edit&amp;section=17" title="Edit section: References">edit</a>]</span> <span class="mw-headline">References</span></h2>
<ul>
<li>Huffman's original article: D.A. Huffman, "<a href="http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=4051119" class="external autonumber" title="http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=4051119" rel="nofollow">[3]</a>" (PDF), Proceedings of the I.R.E., sept 1952, pp 1098-1102</li>
<li>Background story: <a href="http://www.huffmancoding.com/david/scientific.html" class="external text" title="http://www.huffmancoding.com/david/scientific.html" rel="nofollow">Profile: David A. Huffman</a>, <a href="http://en.wikipedia.org/wiki/Scientific_American" title="Scientific American">Scientific American</a>, Sept. 1991, pp. 54-58</li>
<li><a href="http://en.wikipedia.org/wiki/Thomas_H._Cormen" title="Thomas H. Cormen">Thomas H. Cormen</a>, <a href="http://en.wikipedia.org/wiki/Charles_E._Leiserson" title="Charles E. Leiserson">Charles E. Leiserson</a>, <a href="http://en.wikipedia.org/wiki/Ronald_L._Rivest" title="Ronald L. Rivest">Ronald L. Rivest</a>, and <a href="http://en.wikipedia.org/wiki/Clifford_Stein" title="Clifford Stein">Clifford Stein</a>. <i><a href="http://en.wikipedia.org/wiki/Introduction_to_Algorithms" title="Introduction to Algorithms">Introduction to Algorithms</a></i>, Second Edition. MIT Press and McGraw-Hill, 2001. <a href="http://en.wikipedia.org/w/index.php?title=Special:Booksources&amp;isbn=0262032937" class="internal">ISBN 0-262-03293-7</a>. Section 16.3, pp.385–392.</li>
</ul>
<p><a name="External_links" id="External_links"></a></p>
<h2><span class="editsection">[<a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=edit&amp;section=18" title="Edit section: External links">edit</a>]</span> <span class="mw-headline">External links</span></h2>
<div class="infobox sisterproject">
<div class="floatleft"><span><a href="http://en.wikipedia.org/wiki/Image:Commons-logo.svg" class="image" title=""><img alt="" longdesc="/wiki/Image:Commons-logo.svg" src="Huffman_coding_files/50px-Commons-logo.png" height="67" width="50"></a></span></div>
<div style="margin-left: 60px;"><a href="http://en.wikipedia.org/wiki/Wikimedia_Commons" title="Wikimedia Commons">Wikimedia Commons</a> has media related to:
<div style="margin-left: 10px;"><i><b><a href="http://commons.wikimedia.org/wiki/Category:Huffman_coding" class="extiw" title="commons:Category:Huffman_coding">Huffman coding</a></b></i></div>
</div>
</div>
<ul>
<li><a href="http://www.huffmancoding.com/david/algorithm.html" class="external text" title="http://www.huffmancoding.com/david/algorithm.html" rel="nofollow">Program for explaining the Huffman Coding procedure.</a></li>
<li><a href="http://www.cs.sfu.ca/cs/CC/365/li/squeeze" class="external text" title="http://www.cs.sfu.ca/cs/CC/365/li/squeeze" rel="nofollow">Huffman Code Applet</a></li>
<li><a href="http://alexvn.freeservers.com/s1/huffman_template_algorithm.html" class="external text" title="http://alexvn.freeservers.com/s1/huffman_template_algorithm.html" rel="nofollow">n-ary Huffman Template Algorithm</a></li>
<li><a href="http://mathforum.org/discuss/sci.math/t/632220" class="external text" title="http://mathforum.org/discuss/sci.math/t/632220" rel="nofollow">Huffman codes' connection with Fibonacci and Lucas numbers</a></li>
<li><a href="http://www.research.att.com/projects/OEIS?Anum=A098950" class="external text" title="http://www.research.att.com/projects/OEIS?Anum=A098950" rel="nofollow">Sloane A098950</a> Minimizing k-ordered sequences of maximum height Huffman tree</li>
<li><a href="http://semillon.wpi.edu/%7Eaofa/AofA/msg00040.html" class="external text" title="http://semillon.wpi.edu/~aofa/AofA/msg00040.html" rel="nofollow">Computing Huffman codes on a Turing Machine</a></li>
<li>Mordecai J. Golin, Claire Kenyon, Neal E. Young "<a href="http://www.cs.ust.hk/faculty/golin/pubs/LOP_PTAS_STOC.pdf" class="external text" title="http://www.cs.ust.hk/faculty/golin/pubs/LOP_PTAS_STOC.pdf" rel="nofollow">Huffman coding with unequal letter costs</a>" (PDF), <a href="http://www.informatik.uni-trier.de/%7Eley/db/conf/stoc/stoc2002.html" class="external text" title="http://www.informatik.uni-trier.de/~ley/db/conf/stoc/stoc2002.html" rel="nofollow">STOC 2002</a>: 785-791</li>
<li><a href="http://gumuz.looze.net/wordpress/index.php/archives/2004/11/25/huffman-encoding/" class="external text" title="http://gumuz.looze.net/wordpress/index.php/archives/2004/11/25/huffman-encoding/" rel="nofollow">Huffman Coding, implemented in python</a></li>
<li><a href="http://www.cs.duke.edu/csed/poop/huff/info/" class="external text" title="http://www.cs.duke.edu/csed/poop/huff/info/" rel="nofollow">Huffman Coding: A CS2 Assignment</a> a good introduction to Huffman coding</li>
<li><a href="http://www.siggraph.org/education/materials/HyperGraph/video/mpeg/mpegfaq/huffman_tutorial.html" class="external text" title="http://www.siggraph.org/education/materials/HyperGraph/video/mpeg/mpegfaq/huffman_tutorial.html" rel="nofollow">A quick tutorial on generating a Huffman tree</a></li>
<li>Pointers to <a href="http://web-cat.cs.vt.edu/AlgovizWiki/HuffmanCodingTrees" class="external text" title="http://web-cat.cs.vt.edu/AlgovizWiki/HuffmanCodingTrees" rel="nofollow">Huffman coding visualizations</a></li>
<li><a href="http://wiki.cc/php/?title=Huffman" class="external text" title="http://wiki.cc/php/?title=Huffman" rel="nofollow">Huffman for PHP</a></li>
<li><a href="http://huffman.sourceforge.net/" class="external text" title="http://huffman.sourceforge.net" rel="nofollow">Huffman in C</a></li>
<li><a href="http://apollonic.net/code/" class="external text" title="http://apollonic.net/code/" rel="nofollow">Huffman in Java</a></li>
</ul>
<div id="NavFrame1" style="clear: both;" class="NavFrame">
<div class="NavHead" style="background-color: rgb(204, 204, 255);"><a href="http://en.wikipedia.org/wiki/Data_Compression" title="Data Compression">Data Compression Methods</a>
<div class="noprint plainlinksneverexpand" style="padding: 0pt; background-color: transparent; font-weight: normal; font-size: xx-small; color: rgb(0, 0, 0); white-space: nowrap; position: absolute; top: 0px; left: 3px;"><a href="http://en.wikipedia.org/wiki/Template:Compression_Methods" title="Template:Compression Methods"><span title="View this template">v</span></a>&nbsp;<span style="font-size: 80%;">•</span>&nbsp;<a href="http://en.wikipedia.org/w/index.php?title=Template_talk:Compression_Methods&amp;action=edit" class="new" title="Template talk:Compression Methods"><span style="color: rgb(0, 43, 184);" title="Discussion about this template">d</span></a>&nbsp;<span style="font-size: 80%;">•</span>&nbsp;<a href="http://en.wikipedia.org/w/index.php?title=Template:Compression_Methods&amp;action=edit" class="external text" title="http://en.wikipedia.org/w/index.php?title=Template:Compression_Methods&amp;action=edit" rel="nofollow"><span style="color: rgb(0, 43, 184);" title="You can edit this template. Please use the preview button before saving.">e</span></a></div>
<a href="javascript:toggleNavigationBar(1);" id="NavToggle1" class="NavToggle">[hide]</a></div>
<div class="NavContent">
<table style="border: 0pt none ; margin: auto;" class="toccolours">
<tbody><tr>
<th style="background: rgb(221, 221, 255) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial;"><a href="http://en.wikipedia.org/wiki/Lossless_data_compression" title="Lossless data compression">Lossless compression methods</a></th>
<td>
<table style="width: 100%;">
<tbody><tr>
<td valign="top"><b><a href="http://en.wikipedia.org/wiki/Information_theory" title="Information theory">Theory</a></b>
<hr>
<a href="http://en.wikipedia.org/wiki/Information_entropy" title="Information entropy">Entropy</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Kolmogorov_complexity" title="Kolmogorov complexity">Complexity</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Redundancy_%28information_theory%29" title="Redundancy (information theory)">Redundancy</a></td>
<td valign="top"><b><a href="http://en.wikipedia.org/wiki/Entropy_encoding" title="Entropy encoding">Entropy encoding</a></b>
<hr>
<strong class="selflink">Huffman</strong><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Adaptive_Huffman_coding" title="Adaptive Huffman coding">Adaptive Huffman</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Arithmetic_coding" title="Arithmetic coding">Arithmetic</a> (<a href="http://en.wikipedia.org/wiki/Shannon-Fano_coding" title="Shannon-Fano coding">Shannon-Fano</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Range_encoding" title="Range encoding">Range</a>)<span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Golomb_coding" title="Golomb coding">Golomb</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Exponential-Golomb_coding" title="Exponential-Golomb coding">Exp-Golomb</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Universal_code_%28data_compression%29" title="Universal code (data compression)">Universal</a> (<a href="http://en.wikipedia.org/wiki/Elias_gamma_coding" title="Elias gamma coding">Elias</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Fibonacci_coding" title="Fibonacci coding">Fibonacci</a>)</td>
<td valign="top"><b><a href="http://en.wikipedia.org/wiki/Dictionary_coder" title="Dictionary coder">Dictionary</a></b>
<hr>
<a href="http://en.wikipedia.org/wiki/LZ77_and_LZ78" title="LZ77 and LZ78">LZ77/78</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Lempel-Ziv-Welch" title="Lempel-Ziv-Welch">LZW</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Lempel-Ziv-Oberhumer" title="Lempel-Ziv-Oberhumer">LZO</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/DEFLATE" title="DEFLATE">DEFLATE</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Lempel-Ziv-Markov_algorithm" title="Lempel-Ziv-Markov algorithm">LZMA</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/LZX_%28algorithm%29" title="LZX (algorithm)">LZX</a></td>
<td valign="top"><b>Others</b>
<hr>
<a href="http://en.wikipedia.org/wiki/Run-length_encoding" title="Run-length encoding">RLE</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Burrows-Wheeler_transform" title="Burrows-Wheeler transform">BWT</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Prediction_by_partial_matching" title="Prediction by partial matching">PPM</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Dynamic_Markov_Compression" title="Dynamic Markov Compression">DMC</a></td>
</tr>
</tbody></table>
</td>
</tr>
<tr>
<th style="background: rgb(221, 221, 255) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial;"><a href="http://en.wikipedia.org/wiki/Audio_data_compression" title="Audio data compression">Audio compression methods</a></th>
<td>
<table style="width: 100%;">
<tbody><tr>
<td valign="top"><b><a href="http://en.wikipedia.org/wiki/Acoustics" title="Acoustics">Theory</a></b>
<hr>
<a href="http://en.wikipedia.org/wiki/Convolution" title="Convolution">Convolution</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Sampling_%28signal_processing%29" title="Sampling (signal processing)">Sampling</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem" title="Nyquist–Shannon sampling theorem">Nyquist–Shannon theorem</a></td>
<td valign="top"><b><a href="http://en.wikipedia.org/wiki/Audio_codecs" title="Audio codecs">Audio codecs parts</a></b>
<hr>
<a href="http://en.wikipedia.org/wiki/Linear_predictive_coding" title="Linear predictive coding">LPC</a> (<a href="http://en.wikipedia.org/wiki/Log_Area_Ratios" title="Log Area Ratios">LAR</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Line_spectral_pairs" title="Line spectral pairs">LSP</a>)<span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Warped_Linear_Predictive_Coding" title="Warped Linear Predictive Coding">WLPC</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Code_Excited_Linear_Prediction" title="Code Excited Linear Prediction">CELP</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Algebraic_Code_Excited_Linear_Prediction" title="Algebraic Code Excited Linear Prediction">ACELP</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/A-law_algorithm" title="A-law algorithm">A-law</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/%CE%9C-law_algorithm" title="Μ-law algorithm">μ-law</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Modified_discrete_cosine_transform" title="Modified discrete cosine transform">MDCT</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Fourier_transform" title="Fourier transform">Fourier transform</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Psychoacoustic_model" title="Psychoacoustic model">Psychoacoustic model</a></td>
<td valign="top"><b>Others</b>
<hr>
<a href="http://en.wikipedia.org/wiki/Audio_level_compression" title="Audio level compression">Dynamic range compression</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Speech_encoding" title="Speech encoding">Speech compression</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Sub-band_coding" title="Sub-band coding">Sub-band coding</a></td>
</tr>
</tbody></table>
</td>
</tr>
<tr>
<th style="background: rgb(221, 221, 255) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial;"><a href="http://en.wikipedia.org/wiki/Image_compression" title="Image compression">Image compression methods</a></th>
<td>
<table style="width: 100%;">
<tbody><tr>
<td valign="top"><b>Terms</b>
<hr>
<a href="http://en.wikipedia.org/wiki/Color_space" title="Color space">Color space</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Pixel" title="Pixel">Pixel</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Chroma_subsampling" title="Chroma subsampling">Chroma subsampling</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Compression_artifact" title="Compression artifact">Compression artifact</a></td>
<td valign="top"><b>Methods</b>
<hr>
<a href="http://en.wikipedia.org/wiki/Run-length_encoding" title="Run-length encoding">RLE</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Fractal_compression" title="Fractal compression">Fractal</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Wavelet_compression" title="Wavelet compression">Wavelet</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Set_partitioning_in_hierarchical_trees" title="Set partitioning in hierarchical trees">SPIHT</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Discrete_cosine_transform" title="Discrete cosine transform">DCT</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Karhunen-Lo%C3%A8ve_transform" title="Karhunen-Loève transform">KLT</a></td>
<td valign="top"><b>Others</b>
<hr>
<a href="http://en.wikipedia.org/wiki/Bit_rate" title="Bit rate">Bit rate</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Standard_test_image" title="Standard test image">Test images</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio" title="Peak signal-to-noise ratio">PSNR quality measure</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Quantization_%28image_processing%29" title="Quantization (image processing)">Quantization</a></td>
</tr>
</tbody></table>
</td>
</tr>
<tr>
<th style="background: rgb(221, 221, 255) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial;"><a href="http://en.wikipedia.org/wiki/Video_compression" title="Video compression">Video compression</a></th>
<td>
<table style="width: 100%;">
<tbody><tr>
<td valign="top"><b>Terms</b>
<hr>
<a href="http://en.wikipedia.org/wiki/Video#Characteristics_of_video_streams" title="Video">Video Characteristics</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Film_frame" title="Film frame">Frame</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Video_compression_picture_types" title="Video compression picture types">Frame types</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Video_quality" title="Video quality">Video quality</a></td>
<td valign="top"><b><a href="http://en.wikipedia.org/wiki/Video_codec" title="Video codec">Video codec parts</a></b>
<hr>
<a href="http://en.wikipedia.org/wiki/Motion_compensation" title="Motion compensation">Motion compensation</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Discrete_cosine_transform" title="Discrete cosine transform">DCT</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Quantization_%28signal_processing%29" title="Quantization (signal processing)">Quantization</a></td>
<td valign="top"><b>Others</b>
<hr>
<a href="http://en.wikipedia.org/wiki/Video_codec" title="Video codec">Video codecs</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Rate_distortion_theory" title="Rate distortion theory">Rate distortion theory</a> (<a href="http://en.wikipedia.org/wiki/Constant_bitrate" title="Constant bitrate">CBR</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Average_bit_rate" title="Average bit rate">ABR</a><span style="white-space: nowrap; font-weight: bold;">&nbsp;·</span> <a href="http://en.wikipedia.org/wiki/Variable_bit_rate" title="Variable bit rate">VBR</a>)</td>
</tr>
</tbody></table>
</td>
</tr>
<tr>
<th style="background: rgb(221, 221, 255) none repeat scroll 0%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial;" colspan="2"><b><a href="http://en.wikipedia.org/wiki/Timeline_of_information_theory" title="Timeline of information theory">Timeline of information theory, data compression, and error-correcting codes</a></b></th>
</tr>
</tbody></table>
<p><small>(See <a href="http://en.wikipedia.org/wiki/Template:Compression_Formats" title="Template:Compression Formats">Compression Formats and Standards</a> for formats and <a href="http://en.wikipedia.org/wiki/Template:Compression_Software_Implementations" title="Template:Compression Software Implementations">Compression Software Implementations</a> for codecs)</small></p>
</div>
</div>

<!-- 
Pre-expand include size: 22397 bytes
Post-expand include size: 13877 bytes
Template argument size: 463 bytes
Maximum: 2048000 bytes
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:13883-0!1!0!default!!en!2 and timestamp 20070701205025 -->
<div class="printfooter">
Retrieved from "<a href="http://en.wikipedia.org/wiki/Huffman_coding">http://en.wikipedia.org/wiki/Huffman_coding</a>"</div>
			<div id="catlinks"><p class="catlinks"><a href="http://en.wikipedia.org/wiki/Special:Categories" title="Special:Categories">Categories</a>: <span dir="ltr"><a href="http://en.wikipedia.org/wiki/Category:Lossless_compression_algorithms" title="Category:Lossless compression algorithms">Lossless compression algorithms</a></span> | <span dir="ltr"><a href="http://en.wikipedia.org/wiki/Category:Coding_theory" title="Category:Coding theory">Coding theory</a></span></p></div>			<!-- end content -->
			<div class="visualClear"></div>
		</div>
	</div>
		</div>
		<div id="column-one">
	<div id="p-cactions" class="portlet">
		<h5>Views</h5>
		<div class="pBody">
			<ul>
					 <li id="ca-nstab-main" class="selected"><a href="http://en.wikipedia.org/wiki/Huffman_coding" title="View the content page [alt-shift-c]" accesskey="c">Article</a></li>
					 <li id="ca-talk"><a href="http://en.wikipedia.org/wiki/Talk:Huffman_coding" title="Discussion about the content page [alt-shift-t]" accesskey="t">Discussion</a></li>
					 <li id="ca-edit"><a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=edit" title="You can edit this page. Please use the preview button before saving. [alt-shift-e]" accesskey="e">Edit this page</a></li>
					 <li id="ca-history"><a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;action=history" title="Past versions of this page. [alt-shift-h]" accesskey="h">History</a></li>
				</ul>
		</div>
	</div>
	<div class="portlet" id="p-personal">
		<h5>Personal tools</h5>
		<div class="pBody">
			<ul>
				<li id="pt-login"><a href="http://en.wikipedia.org/w/index.php?title=Special:Userlogin&amp;returnto=Huffman_coding" title="You are encouraged to log in, it is not mandatory however. [alt-shift-o]" accesskey="o">Sign in / create account</a></li>
			</ul>
		</div>
	</div>
	<div class="portlet" id="p-logo">
		<a style="background-image: url(/images/wiki-en.png);" href="http://en.wikipedia.org/wiki/Main_Page" title="Visit the Main Page [alt-shift-z]" accesskey="z"></a>
	</div>
	<script type="text/javascript"> if (window.isMSIE55) fixalpha(); </script>
		<div class="portlet" id="p-navigation">
		<h5>Navigation</h5>
		<div class="pBody">
			<ul>
				<li id="n-Main-page"><a title="Visit the main page [alt-shift-z]" accesskey="z" href="http://en.wikipedia.org/wiki/Main_Page">Main page</a></li>
				<li title="Guides to browsing Wikipedia" id="n-Contents"><a href="http://en.wikipedia.org/wiki/Wikipedia:Contents">Contents</a></li>
				<li title="Featured content — the best of Wikipedia" id="n-Featured-content"><a href="http://en.wikipedia.org/wiki/Wikipedia:Featured_content">Featured content</a></li>
				<li id="n-currentevents"><a href="http://en.wikipedia.org/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li>
				<li id="n-randompage"><a href="http://en.wikipedia.org/wiki/Special:Random" title="Load a random page [alt-shift-x]" accesskey="x">Random article</a></li>
			</ul>
		</div>
	</div>
		<div class="portlet" id="p-interaction">
		<h5>interaction</h5>
		<div class="pBody">
			<ul>
				<li id="n-About-Wikipedia"><a href="http://en.wikipedia.org/wiki/Wikipedia:About">About Wikipedia</a></li>
				<li id="n-portal"><a href="http://en.wikipedia.org/wiki/Wikipedia:Community_Portal" title="About the project, what you can do, where to find things">Community portal</a></li>
				<li id="n-recentchanges"><a href="http://en.wikipedia.org/wiki/Special:Recentchanges" title="The list of recent changes in the wiki. [alt-shift-r]" accesskey="r">Recent changes</a></li>
				<li id="n-uploadwizard"><a href="http://en.wikipedia.org/wiki/Wikipedia:Upload">File upload wizard</a></li>
				<li title="How to contact Wikipedia" id="n-contact"><a href="http://en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact us</a></li>
				<li title="Help keep Wikipedia running" id="n-sitesupport"><a href="http://wikimediafoundation.org/wiki/Fundraising" title="Support us">Make a donation</a></li>
				<li title="The place to find out about Wikipedia" id="n-help"><a href="http://en.wikipedia.org/wiki/Help:Contents" title="The place to find out.">Help</a></li>
			</ul>
		</div>
	</div>
		<div id="p-search" class="portlet">
		<h5><label for="searchInput">Search</label></h5>
		<div id="searchBody" class="pBody">
			<form action="/wiki/Special:Search" id="searchform"><div>
				<input id="searchInput" name="search" title="Search Wikipedia [alt-shift-f]" accesskey="f" value="" type="text">
				<input name="go" class="searchButton" id="searchGoButton" value="Go" type="submit">&nbsp;
				<input name="fulltext" class="searchButton" id="mw-searchButton" value="Search" type="submit">
			</div></form>
		</div>
	</div>
	<div class="portlet" id="p-tb">
		<h5>Toolbox</h5>
		<div class="pBody">
			<ul>
				<li id="t-whatlinkshere"><a href="http://en.wikipedia.org/wiki/Special:Whatlinkshere/Huffman_coding" title="List of all wiki pages that link here [alt-shift-j]" accesskey="j">What links here</a></li>
				<li id="t-recentchangeslinked"><a href="http://en.wikipedia.org/wiki/Special:Recentchangeslinked/Huffman_coding" title="Recent changes in pages linked from this page [alt-shift-k]" accesskey="k">Related changes</a></li>
<li id="t-upload"><a href="http://en.wikipedia.org/wiki/Special:Upload" title="Upload images or media files [alt-shift-u]" accesskey="u">Upload file</a></li>
<li id="t-specialpages"><a href="http://en.wikipedia.org/wiki/Special:Specialpages" title="List of all special pages [alt-shift-q]" accesskey="q">Special pages</a></li>
				<li title="Printable version of this page" id="t-print"><a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;printable=yes" title="Printable version of this page [alt-shift-p]" accesskey="p">Printable version</a></li>				<li title="Permanent link to this version of the page" id="t-permalink"><a href="http://en.wikipedia.org/w/index.php?title=Huffman_coding&amp;oldid=141582989" title="Permanent link to this version of the page">Permanent link</a></li><li title="Cite this Wikipedia article" id="t-cite"><a href="http://en.wikipedia.org/w/index.php?title=Special:Cite&amp;page=Huffman_coding&amp;id=141582989">Cite this article</a></li>			</ul>
		</div>
	</div>
	<div id="p-lang" class="portlet">
		<h5>In other languages</h5>
		<div class="pBody">
			<ul>
				<li class="interwiki-ar"><a href="http://ar.wikipedia.org/wiki/%D8%AA%D8%B4%D9%81%D9%8A%D8%B1_%D9%87%D9%88%D9%81%D9%85%D8%A7%D9%86">العربية</a></li>
				<li class="interwiki-cs"><a href="http://cs.wikipedia.org/wiki/Huffmanovo_k%C3%B3dov%C3%A1n%C3%AD">Česky</a></li>
				<li class="interwiki-de"><a href="http://de.wikipedia.org/wiki/Shannon-Fano-Kodierung">Deutsch</a></li>
				<li class="interwiki-es"><a href="http://es.wikipedia.org/wiki/Codificaci%C3%B3n_Huffman">Español</a></li>
				<li class="interwiki-fr"><a href="http://fr.wikipedia.org/wiki/Codage_de_Huffman">Français</a></li>
				<li class="interwiki-ko"><a href="http://ko.wikipedia.org/wiki/%ED%97%88%ED%94%84%EB%A7%8C_%EC%BD%94%EB%94%A9">한국어</a></li>
				<li class="interwiki-it"><a href="http://it.wikipedia.org/wiki/Codifica_di_Huffman">Italiano</a></li>
				<li class="interwiki-he"><a href="http://he.wikipedia.org/wiki/%D7%A7%D7%95%D7%93_%D7%94%D7%95%D7%A4%D7%9E%D7%9F">עברית</a></li>
				<li class="interwiki-nl"><a href="http://nl.wikipedia.org/wiki/Huffmancodering">Nederlands</a></li>
				<li class="interwiki-ja"><a href="http://ja.wikipedia.org/wiki/%E3%83%8F%E3%83%95%E3%83%9E%E3%83%B3%E7%AC%A6%E5%8F%B7">日本語</a></li>
				<li class="interwiki-pl"><a href="http://pl.wikipedia.org/wiki/Kodowanie_Huffmana">Polski</a></li>
				<li class="interwiki-pt"><a href="http://pt.wikipedia.org/wiki/Codifica%C3%A7%C3%A3o_de_Huffman">Português</a></li>
				<li class="interwiki-ru"><a href="http://ru.wikipedia.org/wiki/%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%A5%D0%B0%D1%84%D1%84%D0%BC%D0%B0%D0%BD%D0%B0">Русский</a></li>
				<li class="interwiki-fi"><a href="http://fi.wikipedia.org/wiki/Huffmanin_koodaus">Suomi</a></li>
				<li class="interwiki-sv"><a href="http://sv.wikipedia.org/wiki/Huffmankodning">Svenska</a></li>
				<li class="interwiki-th"><a href="http://th.wikipedia.org/wiki/%E0%B8%A3%E0%B8%AB%E0%B8%B1%E0%B8%AA%E0%B8%AE%E0%B8%B1%E0%B8%9F%E0%B9%81%E0%B8%A1%E0%B8%99_%E0%B9%81%E0%B8%A5%E0%B8%B0_%E0%B8%A3%E0%B8%AB%E0%B8%B1%E0%B8%AA%E0%B9%81%E0%B8%8A%E0%B8%99%E0%B8%99%E0%B8%AD%E0%B8%99-%E0%B8%9F%E0%B8%B2%E0%B9%82%E0%B8%99">ไทย</a></li>
				<li class="interwiki-zh"><a href="http://zh.wikipedia.org/wiki/%E5%93%88%E5%A4%AB%E6%9B%BC%E6%A0%91">中文</a></li>
			</ul>
		</div>
	</div>
		</div><!-- end of the left (by default at least) column -->
			<div class="visualClear"></div>
			<div id="footer">
				<div id="f-poweredbyico"><a href="http://www.mediawiki.org/"><img src="Huffman_coding_files/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki"></a></div>
				<div id="f-copyrightico"><a href="http://wikimediafoundation.org/"><img src="Huffman_coding_files/wikimedia-button.png" alt="Wikimedia Foundation" border="0"></a></div>
			<ul id="f-list">
				<li id="lastmod"> This page was last modified 11:40, 30 June 2007.</li>
				<li id="copyright">All text is available under the terms of the <a class="internal" href="http://en.wikipedia.org/wiki/Wikipedia:Text_of_the_GNU_Free_Documentation_License" title="Wikipedia:Text of the GNU Free Documentation License">GNU Free Documentation License</a>. (See <b><a class="internal" href="http://en.wikipedia.org/wiki/Wikipedia:Copyrights" title="Wikipedia:Copyrights">Copyrights</a></b> for details.) <br> Wikipedia® is a registered trademark of the <a href="http://www.wikimediafoundation.org/">Wikimedia Foundation, Inc</a>., a US-registered <a class="internal" href="http://en.wikipedia.org/wiki/501%28c%29#501.28c.29.283.29" title="501(c)(3)">501(c)(3)</a> <a href="http://wikimediafoundation.org/wiki/Deductibility_of_donations">tax-deductible</a> <a class="internal" href="http://en.wikipedia.org/wiki/Non-profit_organization" title="Non-profit organization">nonprofit</a> <a href="http://en.wikipedia.org/wiki/Charitable_organization" title="Charitable organization">charity</a>.<br></li>
				<li id="privacy"><a href="http://wikimediafoundation.org/wiki/Privacy_policy" title="wikimedia:Privacy policy">Privacy policy</a></li>
				<li id="about"><a href="http://en.wikipedia.org/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
				<li id="disclaimer"><a href="http://en.wikipedia.org/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
			</ul>
		</div>
		
	
		<script type="text/javascript">if (window.runOnloadHook) runOnloadHook();</script>
</div>
<!-- Served by srv102 in 0.071 secs. --></body></html>